{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6af48ba",
   "metadata": {},
   "source": [
    "# Our input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734fa690",
   "metadata": {},
   "source": [
    "A data set containing lots of information about each participent in a speed dating event,such as his  unique subject number,wether he was a male or female, information about each wave such as the number of people he/she met in a wave,station number where met partner,partner's id, wether the participant and the partner were the same race, information about the partner him/her self such as their race,their age,their decision and their rating from 1 to 6...etc.\n",
    "\n",
    "The dataset also contained information collected from a Survey filled out by students that are interested in participating in order to register for the event Like age,field pf study and each field has its own code in our data set,their Median SAT score for their undergraduate institution and also some questions like How important was it to him/her (on a scale of 1-10) that a person they date be of the same racial/ethnic background or e be of the same religious background, and where were they originally from amd the zip code for the place they grew up in, their goal of paticipating in the event , their career, how happy does he/she expect to be with the people they meet during the speed-dating event .. etc.\n",
    "\n",
    "It also had informatiom out of a survey Filled out by subjects after each date during the event, the survey required information like their id,their decision and answers for questions about each person they meet like their attributes,how much they like the person..etc.\n",
    "\n",
    "It has also answers from each participent on Half way through meeting asking about what We want to know what each participent look for in the opposite sex.\n",
    "\n",
    "Also it has information collected from a Survey filled out the day after participating in the event like how satisfied were they with the people they met,What do they think the opposite sex looks for in a date,How does each participent think he/she measures up...etc.\n",
    "\n",
    "Last but not least,Subjects filled out 3-4 weeks after they had been sent their matches and the data set included information regarding that such as How many of the matches each paticipent had has he/she contacted to set up a date, Have the participent been on a date with any of his/her matches and how many....etc.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda58cb2",
   "metadata": {},
   "source": [
    "# Our output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435994ef",
   "metadata": {},
   "source": [
    "Our model is required to predict the outcome of a specific speed dating session based on the profile of two people in order to implement a recommendation system to better match people in speed dating events. we are going to predict the probability that the dating session will lead to a successful match."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5b282b",
   "metadata": {},
   "source": [
    "# What data mining function is required?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2479b0b1",
   "metadata": {},
   "source": [
    "binary classification using pipelines,grid search,Random Search and Bayesian Search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b156e2c",
   "metadata": {},
   "source": [
    "# What could be the challenges?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f0824c",
   "metadata": {},
   "source": [
    "Developing a successful solution to our problem , complex data,datasets can include complex data elements ,another thing is that we have to make sure that our algorithm must be efficient and scalable to extract information from the big data and we should have enough knowledge and experience in order to use them if we needed to improve our algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debab9dc",
   "metadata": {},
   "source": [
    "# What is the impact?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eab230",
   "metadata": {},
   "source": [
    "Our model predictions is going to implement a recommendation system to better match people in speed dating events which will make it easier when it comes to dating "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7b2274",
   "metadata": {},
   "source": [
    "# What is an ideal solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d061944",
   "metadata": {},
   "source": [
    " An ideal solution in my opinion will be measured in terms of metrics and performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0791be11",
   "metadata": {},
   "source": [
    "# What is the experimental protocol used and how was it carried out? What preprocessing steps are used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b236438",
   "metadata": {},
   "source": [
    "when it comes to the preprocessing steps I made a pipeline performing the following on the training set and testing set :\n",
    "\n",
    "SimpleImputer(),Imputation transformer for completing missing values.\n",
    "\n",
    "one hot encoder to transform categorical data to numerical data\n",
    "\n",
    "stadnard scalar to standard scale my data \n",
    "\n",
    "The experimental protocol I used in my code is cross validation and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747c71f6",
   "metadata": {},
   "source": [
    "# Why a simple linear regression model (without any activation function) is not good for classification task, compared to Perceptron/Logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554477cb",
   "metadata": {},
   "source": [
    "Continuous values are predicted and dealt with by linear regression, whereas discrete values are predicted and dealt with by classification. The second issue is that when new data points are added, the threshold value shifts.\n",
    "\n",
    "While a Categorical value, such as 0 or 1, Yes or No, is the result of Logistic Regression/perceptron.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90612b9",
   "metadata": {},
   "source": [
    "# What's a decision tree and how it is different to a logistic regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeab027c",
   "metadata": {},
   "source": [
    "A decision tree is a tool with a tree-like structure that predicts likely outcomes, resource costs, utility costs, and potential implications. Decision trees are a mechanism to provide conditional control assertions in algorithms. They have branches that indicate decision-making steps that could result in a positive outcome.\n",
    "\n",
    "Decision Trees divide the space into smaller and smaller sections, whereas Logistic Regression fits a single line to precisely divide the space into two. These lines would, of course, generalise to planes and hyperplanes for higher-dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e58b0a8",
   "metadata": {},
   "source": [
    "# What's the difference between grid search and random search?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7458a964",
   "metadata": {},
   "source": [
    "GridSearchCV differs from RandomizedSearchCV in that in Grid Search, we test every combination of a preset list of hyper-parameter values and chose the best one based on the cross-validation score. Random search tries a variety of different values at random (we have to define the number iterations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7b3b44",
   "metadata": {},
   "source": [
    "# What's the difference between bayesian search and random search?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3433ad",
   "metadata": {},
   "source": [
    "Because they select hyperparameters in an informed manner, Bayesian optimization methods are efficient. Bayesian approaches can locate the best hyperparameters in less time (fewer iterations) than grid search and random search because they prioritise hyperparameters that appear more promising from previous findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07666656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #I imported pandas cause Using it\n",
    "#make it way easier when it comes to  processing, analysis and manipulation of data\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3817ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
      "id                                                                           \n",
      "2583       0    3       2    14     18         2       2.0     14       12   \n",
      "6830       1   14       1     3     10         2       NaN      8        8   \n",
      "4840       1   14       1    13     10         8       8.0     10       10   \n",
      "5508       1   38       2     9     20        18      13.0      6        7   \n",
      "4828       1   24       2    14     20         6       6.0     20       17   \n",
      "...      ...  ...     ...   ...    ...       ...       ...    ...      ...   \n",
      "3390       0    1       2     9     20         2       2.0     18        1   \n",
      "4130       1   24       2     9     20        19      15.0      5        6   \n",
      "1178       0   13       2    11     21         5       5.0      3       18   \n",
      "5016       1   10       2     7     16         6      14.0      9       10   \n",
      "8149       0    7       2    21     22         7       7.0      2       12   \n",
      "\n",
      "        pid  ...  attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  \\\n",
      "id           ...                                                        \n",
      "2583  372.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "6830   63.0  ...      6.0      8.0       8.0     7.0     8.0      NaN   \n",
      "4840  331.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "5508  200.0  ...      8.0      9.0       8.0     8.0     6.0      NaN   \n",
      "4828  357.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "...     ...  ...      ...      ...       ...     ...     ...      ...   \n",
      "3390  214.0  ...     12.0     12.0      12.0     9.0    12.0      NaN   \n",
      "4130  199.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "1178  290.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "5016  151.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "8149  542.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "\n",
      "      sinc5_3  intel5_3  fun5_3  amb5_3  \n",
      "id                                       \n",
      "2583      NaN       NaN     NaN     NaN  \n",
      "6830      NaN       NaN     NaN     NaN  \n",
      "4840      NaN       NaN     NaN     NaN  \n",
      "5508      NaN       NaN     NaN     NaN  \n",
      "4828      NaN       NaN     NaN     NaN  \n",
      "...       ...       ...     ...     ...  \n",
      "3390      NaN       NaN     NaN     NaN  \n",
      "4130      NaN       NaN     NaN     NaN  \n",
      "1178      NaN       NaN     NaN     NaN  \n",
      "5016      NaN       NaN     NaN     NaN  \n",
      "8149      NaN       NaN     NaN     NaN  \n",
      "\n",
      "[5909 rows x 191 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv') #I imported my training data set\n",
    "# Set column \"id\" as index column\n",
    "df.set_index(\"id\", inplace = True)\n",
    "print(df) #printing my training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eb0902b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
      "id                                                                           \n",
      "934        0    5       2     2     16         3       NaN     13       13   \n",
      "6539       0   33       2    14     18         6       6.0      4        8   \n",
      "6757       1    6       2     9     20        10      16.0     15       19   \n",
      "2275       1   26       2     2     19        15       NaN      8       10   \n",
      "1052       0   29       2     7     16         7       7.0     10        5   \n",
      "...      ...  ...     ...   ...    ...       ...       ...    ...      ...   \n",
      "7982       0   23       2    15     19        18      18.0     14       11   \n",
      "7299       0    5       1    13      9         4       4.0      4        8   \n",
      "1818       1   26       2     2     19         3       NaN     15        3   \n",
      "937        0   19       2     9     20        11      11.0      9        2   \n",
      "6691       1   38       2    21     22        22       7.0     16        5   \n",
      "\n",
      "        pid  ...  attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  \\\n",
      "id           ...                                                        \n",
      "934    52.0  ...      5.0      7.0       8.0     6.0     8.0      NaN   \n",
      "6539  368.0  ...      6.0      8.0       7.0     7.0     8.0      6.0   \n",
      "6757  212.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "2275   30.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "1052  162.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "...     ...  ...      ...      ...       ...     ...     ...      ...   \n",
      "7982  407.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "7299  339.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "1818   23.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "937   215.0  ...      9.0      7.0      12.0    12.0     9.0      NaN   \n",
      "6691  513.0  ...      7.0      9.0       8.0     7.0     8.0      5.0   \n",
      "\n",
      "      sinc5_3  intel5_3  fun5_3  amb5_3  \n",
      "id                                       \n",
      "934       NaN       NaN     NaN     NaN  \n",
      "6539      7.0       6.0     5.0     5.0  \n",
      "6757      NaN       NaN     NaN     NaN  \n",
      "2275      NaN       NaN     NaN     NaN  \n",
      "1052      NaN       NaN     NaN     NaN  \n",
      "...       ...       ...     ...     ...  \n",
      "7982      NaN       NaN     NaN     NaN  \n",
      "7299      NaN       NaN     NaN     NaN  \n",
      "1818      NaN       NaN     NaN     NaN  \n",
      "937       NaN       NaN     NaN     NaN  \n",
      "6691      8.0       8.0     6.0     8.0  \n",
      "\n",
      "[2469 rows x 190 columns]\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('test.csv') #I imported my testing data set\n",
    "# Set column \"id\" as index column\n",
    "df2.set_index(\"id\", inplace = True)\n",
    "print(df2) #printing my testing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ff03b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5909, 191)\n",
      "(2469, 190)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)#shape of training set\n",
    "print(df2.shape)#shape of testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ea9705b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_in_3    5449\n",
       "numdat_3    4849\n",
       "expnum      4627\n",
       "amb7_2      4519\n",
       "sinc7_2     4519\n",
       "            ... \n",
       "order          0\n",
       "partner        0\n",
       "match          0\n",
       "samerace       0\n",
       "gender         0\n",
       "Length: 191, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing data\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc65d912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_in_3    2261\n",
       "numdat_3    2033\n",
       "expnum      1951\n",
       "sinc7_2     1904\n",
       "amb7_2      1904\n",
       "            ... \n",
       "position       0\n",
       "round          0\n",
       "wave           0\n",
       "condtn         0\n",
       "gender         0\n",
       "Length: 190, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#same for testing set\n",
    "df2.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ca52d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have a lot of nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76e1f884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5909 entries, 2583 to 8149\n",
      "Columns: 191 entries, gender to amb5_3\n",
      "dtypes: float64(173), int64(10), object(8)\n",
      "memory usage: 8.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# checking types of columns in trainig set :\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18de9840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2469 entries, 934 to 6691\n",
      "Columns: 190 entries, gender to amb5_3\n",
      "dtypes: float64(173), int64(9), object(8)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# checking types of columns in testing set :\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18a6266d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['field',\n",
       " 'undergra',\n",
       " 'mn_sat',\n",
       " 'tuition',\n",
       " 'from',\n",
       " 'zipcode',\n",
       " 'income',\n",
       " 'career']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seems like I have 8 object columns, I'm going to get the names of those object columns,\n",
    "catCols = [col for col in df.columns if df[col].dtype==\"O\"]\n",
    "#display their names\n",
    "catCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "224aeaf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "2583    Ed.D. in higher education policy at TC\n",
       "6830                               Engineering\n",
       "4840                            Urban Planning\n",
       "5508                     International Affairs\n",
       "4828                                  Business\n",
       "                         ...                  \n",
       "3390                       Clinical Psychology\n",
       "4130                                       MBA\n",
       "1178                      MA Science Education\n",
       "5016                              Biochemistry\n",
       "8149                        MFA Acting Program\n",
       "Name: field, Length: 5909, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['field'] #display field column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1de8c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for those object columns,I'll use categorical encoding to change their types from object to category in both training and\n",
    "#testing data\n",
    "df['field'] = df['field'].astype(\"category\")\n",
    "df2['field'] = df2['field'].astype(\"category\")\n",
    "df2['undergra'] = df2['undergra'].astype(\"category\")\n",
    "df['undergra'] = df['undergra'].astype(\"category\")\n",
    "df['mn_sat'] = df['mn_sat'].astype(\"category\")\n",
    "df2['mn_sat'] = df2['mn_sat'].astype(\"category\")\n",
    "df['tuition'] = df['tuition'].astype(\"category\")\n",
    "df2['tuition'] = df2['tuition'].astype(\"category\")\n",
    "df['from'] = df['from'].astype(\"category\")\n",
    "df2['from'] = df2['from'].astype(\"category\")\n",
    "df['zipcode'] = df['zipcode'].astype(\"category\")\n",
    "df2['zipcode'] = df2['zipcode'].astype(\"category\")\n",
    "df['income'] = df['income'].astype(\"category\")\n",
    "df2['income'] = df2['income'].astype(\"category\")\n",
    "df['career'] = df['career'].astype(\"category\")\n",
    "df2['career'] = df2['career'].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8595530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
      "id                                                                           \n",
      "2583       0    3       2    14     18         2       2.0     14       12   \n",
      "6830       1   14       1     3     10         2       NaN      8        8   \n",
      "4840       1   14       1    13     10         8       8.0     10       10   \n",
      "5508       1   38       2     9     20        18      13.0      6        7   \n",
      "4828       1   24       2    14     20         6       6.0     20       17   \n",
      "...      ...  ...     ...   ...    ...       ...       ...    ...      ...   \n",
      "3390       0    1       2     9     20         2       2.0     18        1   \n",
      "4130       1   24       2     9     20        19      15.0      5        6   \n",
      "1178       0   13       2    11     21         5       5.0      3       18   \n",
      "5016       1   10       2     7     16         6      14.0      9       10   \n",
      "8149       0    7       2    21     22         7       7.0      2       12   \n",
      "\n",
      "        pid  ...  attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  \\\n",
      "id           ...                                                        \n",
      "2583  372.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "6830   63.0  ...      6.0      8.0       8.0     7.0     8.0      NaN   \n",
      "4840  331.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "5508  200.0  ...      8.0      9.0       8.0     8.0     6.0      NaN   \n",
      "4828  357.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "...     ...  ...      ...      ...       ...     ...     ...      ...   \n",
      "3390  214.0  ...     12.0     12.0      12.0     9.0    12.0      NaN   \n",
      "4130  199.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "1178  290.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "5016  151.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "8149  542.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "\n",
      "      sinc5_3  intel5_3  fun5_3  amb5_3  \n",
      "id                                       \n",
      "2583      NaN       NaN     NaN     NaN  \n",
      "6830      NaN       NaN     NaN     NaN  \n",
      "4840      NaN       NaN     NaN     NaN  \n",
      "5508      NaN       NaN     NaN     NaN  \n",
      "4828      NaN       NaN     NaN     NaN  \n",
      "...       ...       ...     ...     ...  \n",
      "3390      NaN       NaN     NaN     NaN  \n",
      "4130      NaN       NaN     NaN     NaN  \n",
      "1178      NaN       NaN     NaN     NaN  \n",
      "5016      NaN       NaN     NaN     NaN  \n",
      "8149      NaN       NaN     NaN     NaN  \n",
      "\n",
      "[5909 rows x 191 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df) #printing my training set after categorical enconding for its 8 object columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc2203a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
      "id                                                                           \n",
      "934        0    5       2     2     16         3       NaN     13       13   \n",
      "6539       0   33       2    14     18         6       6.0      4        8   \n",
      "6757       1    6       2     9     20        10      16.0     15       19   \n",
      "2275       1   26       2     2     19        15       NaN      8       10   \n",
      "1052       0   29       2     7     16         7       7.0     10        5   \n",
      "...      ...  ...     ...   ...    ...       ...       ...    ...      ...   \n",
      "7982       0   23       2    15     19        18      18.0     14       11   \n",
      "7299       0    5       1    13      9         4       4.0      4        8   \n",
      "1818       1   26       2     2     19         3       NaN     15        3   \n",
      "937        0   19       2     9     20        11      11.0      9        2   \n",
      "6691       1   38       2    21     22        22       7.0     16        5   \n",
      "\n",
      "        pid  ...  attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  \\\n",
      "id           ...                                                        \n",
      "934    52.0  ...      5.0      7.0       8.0     6.0     8.0      NaN   \n",
      "6539  368.0  ...      6.0      8.0       7.0     7.0     8.0      6.0   \n",
      "6757  212.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "2275   30.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "1052  162.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "...     ...  ...      ...      ...       ...     ...     ...      ...   \n",
      "7982  407.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "7299  339.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "1818   23.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
      "937   215.0  ...      9.0      7.0      12.0    12.0     9.0      NaN   \n",
      "6691  513.0  ...      7.0      9.0       8.0     7.0     8.0      5.0   \n",
      "\n",
      "      sinc5_3  intel5_3  fun5_3  amb5_3  \n",
      "id                                       \n",
      "934       NaN       NaN     NaN     NaN  \n",
      "6539      7.0       6.0     5.0     5.0  \n",
      "6757      NaN       NaN     NaN     NaN  \n",
      "2275      NaN       NaN     NaN     NaN  \n",
      "1052      NaN       NaN     NaN     NaN  \n",
      "...       ...       ...     ...     ...  \n",
      "7982      NaN       NaN     NaN     NaN  \n",
      "7299      NaN       NaN     NaN     NaN  \n",
      "1818      NaN       NaN     NaN     NaN  \n",
      "937       NaN       NaN     NaN     NaN  \n",
      "6691      8.0       8.0     6.0     8.0  \n",
      "\n",
      "[2469 rows x 190 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df2) #printing my testing set after categorical enconding for its 8 object columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9578ff51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5909 entries, 2583 to 8149\n",
      "Columns: 191 entries, gender to amb5_3\n",
      "dtypes: category(8), float64(173), int64(10)\n",
      "memory usage: 8.5 MB\n"
     ]
    }
   ],
   "source": [
    "# checking types again:\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72910aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>partner</th>\n",
       "      <th>pid</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>372.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6830</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4840</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>331.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5508</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4828</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>357.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>214.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>199.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>290.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8149</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>542.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5909 rows Ã— 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
       "id                                                                           \n",
       "2583       0    3       2    14     18         2       2.0     14       12   \n",
       "6830       1   14       1     3     10         2       NaN      8        8   \n",
       "4840       1   14       1    13     10         8       8.0     10       10   \n",
       "5508       1   38       2     9     20        18      13.0      6        7   \n",
       "4828       1   24       2    14     20         6       6.0     20       17   \n",
       "...      ...  ...     ...   ...    ...       ...       ...    ...      ...   \n",
       "3390       0    1       2     9     20         2       2.0     18        1   \n",
       "4130       1   24       2     9     20        19      15.0      5        6   \n",
       "1178       0   13       2    11     21         5       5.0      3       18   \n",
       "5016       1   10       2     7     16         6      14.0      9       10   \n",
       "8149       0    7       2    21     22         7       7.0      2       12   \n",
       "\n",
       "        pid  ...  attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  \\\n",
       "id           ...                                                        \n",
       "2583  372.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "6830   63.0  ...      6.0      8.0       8.0     7.0     8.0      NaN   \n",
       "4840  331.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "5508  200.0  ...      8.0      9.0       8.0     8.0     6.0      NaN   \n",
       "4828  357.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "...     ...  ...      ...      ...       ...     ...     ...      ...   \n",
       "3390  214.0  ...     12.0     12.0      12.0     9.0    12.0      NaN   \n",
       "4130  199.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "1178  290.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "5016  151.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "8149  542.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "\n",
       "      sinc5_3  intel5_3  fun5_3  amb5_3  \n",
       "id                                       \n",
       "2583      NaN       NaN     NaN     NaN  \n",
       "6830      NaN       NaN     NaN     NaN  \n",
       "4840      NaN       NaN     NaN     NaN  \n",
       "5508      NaN       NaN     NaN     NaN  \n",
       "4828      NaN       NaN     NaN     NaN  \n",
       "...       ...       ...     ...     ...  \n",
       "3390      NaN       NaN     NaN     NaN  \n",
       "4130      NaN       NaN     NaN     NaN  \n",
       "1178      NaN       NaN     NaN     NaN  \n",
       "5016      NaN       NaN     NaN     NaN  \n",
       "8149      NaN       NaN     NaN     NaN  \n",
       "\n",
       "[5909 rows x 190 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing numpy library and Splitting the data into features and target variables\n",
    "import numpy as np\n",
    "Xtr=df.drop('match', axis=1)#here I started splitting my training set (df) into Xtr (input)\n",
    "ytr=df['match'] #and ytr the output (my target) which is the matching\n",
    "Xts=df2 #my xtest which is equal to the testing dataframe\n",
    "Xtr #displaying my x train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3aec847b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>partner</th>\n",
       "      <th>pid</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6539</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>368.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6757</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>212.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>162.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7982</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>407.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7299</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>339.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>215.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6691</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>513.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2469 rows Ã— 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
       "id                                                                           \n",
       "934        0    5       2     2     16         3       NaN     13       13   \n",
       "6539       0   33       2    14     18         6       6.0      4        8   \n",
       "6757       1    6       2     9     20        10      16.0     15       19   \n",
       "2275       1   26       2     2     19        15       NaN      8       10   \n",
       "1052       0   29       2     7     16         7       7.0     10        5   \n",
       "...      ...  ...     ...   ...    ...       ...       ...    ...      ...   \n",
       "7982       0   23       2    15     19        18      18.0     14       11   \n",
       "7299       0    5       1    13      9         4       4.0      4        8   \n",
       "1818       1   26       2     2     19         3       NaN     15        3   \n",
       "937        0   19       2     9     20        11      11.0      9        2   \n",
       "6691       1   38       2    21     22        22       7.0     16        5   \n",
       "\n",
       "        pid  ...  attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  \\\n",
       "id           ...                                                        \n",
       "934    52.0  ...      5.0      7.0       8.0     6.0     8.0      NaN   \n",
       "6539  368.0  ...      6.0      8.0       7.0     7.0     8.0      6.0   \n",
       "6757  212.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "2275   30.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "1052  162.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "...     ...  ...      ...      ...       ...     ...     ...      ...   \n",
       "7982  407.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "7299  339.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "1818   23.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
       "937   215.0  ...      9.0      7.0      12.0    12.0     9.0      NaN   \n",
       "6691  513.0  ...      7.0      9.0       8.0     7.0     8.0      5.0   \n",
       "\n",
       "      sinc5_3  intel5_3  fun5_3  amb5_3  \n",
       "id                                       \n",
       "934       NaN       NaN     NaN     NaN  \n",
       "6539      7.0       6.0     5.0     5.0  \n",
       "6757      NaN       NaN     NaN     NaN  \n",
       "2275      NaN       NaN     NaN     NaN  \n",
       "1052      NaN       NaN     NaN     NaN  \n",
       "...       ...       ...     ...     ...  \n",
       "7982      NaN       NaN     NaN     NaN  \n",
       "7299      NaN       NaN     NaN     NaN  \n",
       "1818      NaN       NaN     NaN     NaN  \n",
       "937       NaN       NaN     NaN     NaN  \n",
       "6691      8.0       8.0     6.0     8.0  \n",
       "\n",
       "[2469 rows x 190 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xts #displaying x test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86fac726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "2583    0\n",
       "6830    0\n",
       "4840    0\n",
       "5508    0\n",
       "4828    0\n",
       "       ..\n",
       "3390    0\n",
       "4130    0\n",
       "1178    0\n",
       "5016    1\n",
       "8149    0\n",
       "Name: match, Length: 5909, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytr #displaying my y train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2e36969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric features: ['gender', 'idg', 'condtn', 'wave', 'round', 'position', 'positin1', 'order', 'partner', 'pid', 'int_corr', 'samerace', 'age_o', 'race_o', 'pf_o_att', 'pf_o_sin', 'pf_o_int', 'pf_o_fun', 'pf_o_amb', 'pf_o_sha', 'attr_o', 'sinc_o', 'intel_o', 'fun_o', 'amb_o', 'shar_o', 'like_o', 'prob_o', 'met_o', 'age', 'field_cd', 'race', 'imprace', 'imprelig', 'goal', 'date', 'go_out', 'career_c', 'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'exphappy', 'expnum', 'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1', 'attr4_1', 'sinc4_1', 'intel4_1', 'fun4_1', 'amb4_1', 'shar4_1', 'attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1', 'attr3_1', 'sinc3_1', 'fun3_1', 'intel3_1', 'amb3_1', 'attr5_1', 'sinc5_1', 'intel5_1', 'fun5_1', 'amb5_1', 'attr', 'sinc', 'intel', 'fun', 'amb', 'shar', 'like', 'prob', 'met', 'match_es', 'attr1_s', 'sinc1_s', 'intel1_s', 'fun1_s', 'amb1_s', 'shar1_s', 'attr3_s', 'sinc3_s', 'intel3_s', 'fun3_s', 'amb3_s', 'satis_2', 'length', 'numdat_2', 'attr7_2', 'sinc7_2', 'intel7_2', 'fun7_2', 'amb7_2', 'shar7_2', 'attr1_2', 'sinc1_2', 'intel1_2', 'fun1_2', 'amb1_2', 'shar1_2', 'attr4_2', 'sinc4_2', 'intel4_2', 'fun4_2', 'amb4_2', 'shar4_2', 'attr2_2', 'sinc2_2', 'intel2_2', 'fun2_2', 'amb2_2', 'shar2_2', 'attr3_2', 'sinc3_2', 'intel3_2', 'fun3_2', 'amb3_2', 'attr5_2', 'sinc5_2', 'intel5_2', 'fun5_2', 'amb5_2', 'you_call', 'them_cal', 'date_3', 'numdat_3', 'num_in_3', 'attr1_3', 'sinc1_3', 'intel1_3', 'fun1_3', 'amb1_3', 'shar1_3', 'attr7_3', 'sinc7_3', 'intel7_3', 'fun7_3', 'amb7_3', 'shar7_3', 'attr4_3', 'sinc4_3', 'intel4_3', 'fun4_3', 'amb4_3', 'shar4_3', 'attr2_3', 'sinc2_3', 'intel2_3', 'fun2_3', 'amb2_3', 'shar2_3', 'attr3_3', 'sinc3_3', 'intel3_3', 'fun3_3', 'amb3_3', 'attr5_3', 'sinc5_3', 'intel5_3', 'fun5_3', 'amb5_3']\n",
      "categorical features: ['field', 'undergra', 'mn_sat', 'tuition', 'from', 'zipcode', 'income', 'career']\n"
     ]
    }
   ],
   "source": [
    "#now the pipeline\n",
    "# we extract numeric features and categorical features names\n",
    "\n",
    "# numeric features can be selected by: (based on the df2.info() output )\n",
    "features_numeric = list(Xtr.select_dtypes(include=['float64', 'int64']))\n",
    "\n",
    "# categorical features can be selected by: (based on the df2.info() output )\n",
    "features_categorical = list(Xtr.select_dtypes(include=['category']))\n",
    "\n",
    "print('numeric features:', features_numeric) #printing numeric features\n",
    "print('categorical features:', features_categorical) #printing categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f7377d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['gender', 'idg', 'condtn',\n",
       "                                                   'wave', 'round', 'position',\n",
       "                                                   'positin1', 'order',\n",
       "                                                   'partner', 'pid', 'int_corr',\n",
       "                                                   'samerace', 'age_o',\n",
       "                                                   'race_o', 'pf_o_att',\n",
       "                                                   'pf_o_sin', 'pf_o_int',\n",
       "                                                   'pf_o_fun', 'pf_o_amb',\n",
       "                                                   'pf_o_sha', 'attr_o',\n",
       "                                                   'sinc_o', 'intel_o', 'fun_o',\n",
       "                                                   'amb_o', 'shar_o', 'like_o',\n",
       "                                                   'prob_o', 'met_o', 'age', ...]),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='constant')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['field', 'undergra',\n",
       "                                                   'mn_sat', 'tuition', 'from',\n",
       "                                                   'zipcode', 'income',\n",
       "                                                   'career'])])),\n",
       "                ('my_classifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing important libraries\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "np.random.seed(0) #every time you call the numpy's other random function, the result will be the same\n",
    "\n",
    "# define a pipe line for numeric feature preprocessing\n",
    "# we gave them a name so we can set their hyperparameters\n",
    "transformer_numeric = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer()),#Imputation transformer for completing missing values.\n",
    "        ('scaler', StandardScaler())]#Standardize features\n",
    "\n",
    ")\n",
    "\n",
    "# define a pipe line for categorical feature preprocessing\n",
    "# we gave them a name so we can set their hyperparameters\n",
    "transformer_categorical = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant')), #here I set the strategy for completting missing values  = constant\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore')) #Encode categorical features as a one-hot numeric\n",
    "        #When handle_unknown parameter is set to â€˜ignoreâ€™ and an unknown category is encountered during transform,\n",
    "        #the resulting one-hot encoded columns for this feature will be all zeros.\n",
    "\n",
    "    ]\n",
    ")\n",
    "# define the preprocessor \n",
    "# we gave them a name so we can set their hyperparameters\n",
    "# we also specify what are the categorical \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', transformer_numeric, features_numeric),\n",
    "        ('cat', transformer_categorical, features_categorical)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# combine the preprocessor with the model as a full tunable pipeline\n",
    "# we gave them a name so we can set their hyperparameters\n",
    "full_pipline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('my_classifier', \n",
    "           RandomForestClassifier(), #I want to use random forest classifier\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "full_pipline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6730a8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The pipeline object can be used like any sk-learn model\n",
    "full_pipline = full_pipline.fit(Xtr, ytr) #fitting the data in the pipe\n",
    "full_pipline.predict(Xts) #predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b12ada82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "best score 0.8243617887449464\n",
      "best parameters {'my_classifier__max_depth': 30, 'my_classifier__n_estimators': 150, 'preprocessor__num__imputer__strategy': 'median'}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search with Cross-validation\n",
    "# here we specify the search space\n",
    "param_grid = {\n",
    "    'preprocessor__num__imputer__strategy': ['median'], #I set it to median\n",
    "    'my_classifier__n_estimators': [50, 100, 150],  # ranges of n_estimators which are the number of trees to be used in the forest.\n",
    "    # I set my  n_estimators ranges to [50, 100, 150]\n",
    "    'my_classifier__max_depth':[30, 60, 90]  \n",
    "    # I set my  max depth ranges to [30, 60, 90] which are The number of splits that each decision tree is allowed to make.\n",
    "}\n",
    "\n",
    "# two-fold cross-validation\n",
    "# n_jobs means cucurrent number of jobs is 2\n",
    "grid_search = GridSearchCV(\n",
    "    full_pipline, param_grid, cv=2, verbose=1 # showing more 'wordy' information\n",
    "    , n_jobs=2, \n",
    "    scoring='roc_auc')#The degree of separability/distinction or intermingling/crossover between the forecasts of the two classes is shown by the ROC-AUC.\n",
    "\n",
    "grid_search.fit(Xtr, ytr) #fitting Xtr and ytr\n",
    "\n",
    "print('best score {}'.format(grid_search.best_score_)) #printing best score\n",
    "print('best parameters {}'.format(grid_search.best_params_))#printing best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a2a4fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the resulting model is the same pipeline but with the best hyperparameters\n",
    "# trained on the full training set. we can use it directly\n",
    "ypred=grid_search.predict(Xts) #predicting ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ba4236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame() # creating dataframe for the submission\n",
    "submission['id'] = Xts.index #using the column index of x test values to fill submission['id'] column\n",
    "submission['match'] = grid_search.predict_proba(Xts)[:,1] #predicting the probabilities and filling submission['match'] column with their values\n",
    "submission.to_csv('sample_submission_walkthrough.csv', index=False)#generating the submission file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dbf239",
   "metadata": {},
   "source": [
    "# Trial one using RandomForest with Grid Search with Cross-validation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b231fb5",
   "metadata": {},
   "source": [
    "Cross-validation is a method for robustly estimating test-set performance (generalization) of a model. Grid-searching is the process of scanning the data to configure optimal parameters for a given model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036d41ef",
   "metadata": {},
   "source": [
    "# Expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1906be",
   "metadata": {},
   "source": [
    "I expect to get the optimal hyperparamters that will give me the best performance and highest accuracy using random forest model with grid search and cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d602311f",
   "metadata": {},
   "source": [
    "# Observation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b38552f",
   "metadata": {},
   "source": [
    "After running the code,the best hyperparameters that was defined by the grid search using cross validation were : \n",
    "    \n",
    "max_depth: 30\n",
    "    \n",
    "n_estimators: 150\n",
    "    \n",
    "with using imputer__strategy of: 'median'\n",
    "    \n",
    "The model gave me a best score of 0.8243617887449464\n",
    "\n",
    "Score on kaggle 0.84021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83969d82",
   "metadata": {},
   "source": [
    "# Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f4aae0",
   "metadata": {},
   "source": [
    "I'm going to set different ranges for the hyperparameters in the grid search with cross validation\n",
    "\n",
    "\n",
    "n_estimators': [90, 180, 270 ]\n",
    "    \n",
    "    \n",
    "max_depth':[30, 100, 170]\n",
    "    \n",
    "    \n",
    "and I changed my imputer__strategy' to 'most_frequent'\n",
    "\n",
    "\n",
    "and I changed number of folds to cv=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81ef8ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 9 candidates, totalling 36 fits\n",
      "best score 0.8355541226745274\n",
      "best parameters {'my_classifier__max_depth': 100, 'my_classifier__n_estimators': 270, 'preprocessor__num__imputer__strategy': 'most_frequent'}\n"
     ]
    }
   ],
   "source": [
    "# after changing hyperparameters ranges/values\n",
    "param_grid = {\n",
    "    'preprocessor__num__imputer__strategy': ['most_frequent'], # this is the strategy of completing missing data it will be filled with most frequent  \n",
    "    'my_classifier__n_estimators': [90, 180, 270], #I changed my ranges of the number of trees to be used in the forest into: [90,180,270]\n",
    "    'my_classifier__max_depth':[30, 100, 170]\n",
    "    #  I set my  max depth ranges to [30, 100, 170] which are The number of splits that each decision tree is allowed to make.\n",
    "    \n",
    "}\n",
    "\n",
    "# cv=2 means two-fold cross-validation\n",
    "# n_jobs means the cucurrent number of jobs\n",
    "grid_search = GridSearchCV(\n",
    "    full_pipline, param_grid, cv=4, verbose=1,# showing more 'wordy' information\n",
    "    n_jobs=2, #n_jobs means cucurrent number of jobs is 2\n",
    "    scoring='roc_auc')#The degree of separability/distinction or intermingling/crossover between the forecasts of the two classes is shown by the ROC-AUC.\n",
    "\n",
    "grid_search.fit(Xtr, ytr) #fitting Xtr and ytr\n",
    "\n",
    "print('best score {}'.format(grid_search.best_score_))\n",
    "print('best parameters {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bed4facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the resulting model is the same pipeline with the best hyperparameters\n",
    "# trained on the full training set. we can use it directly\n",
    "ypred=grid_search.predict(Xts) #predicting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79d5f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()# creating dataframe for the submission\n",
    "submission['id'] = Xts.index#using the column index of x test values to fill submission['id'] column\n",
    "submission['match'] = grid_search.predict_proba(Xts)[:,1]#predicting the probabilities and filling submission['match'] column with their values\n",
    "submission.to_csv('sample_submission_walkthrough.csv', index=False)#generating the submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c2d762",
   "metadata": {},
   "source": [
    "# Trial 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a43efb",
   "metadata": {},
   "source": [
    "# Expectation\n",
    "\n",
    "I expected to get a higher accuracy after changing the ranges/values of my model's hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d55953",
   "metadata": {},
   "source": [
    "# Observation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacc8a05",
   "metadata": {},
   "source": [
    "After running the code,the best hyperparameters that was defined by the grid search using cross validation were : \n",
    "    \n",
    "max_depth: 100\n",
    "    \n",
    "n_estimators: 270\n",
    "    \n",
    "with using imputer__strategy of: 'most_frequent'\n",
    "    \n",
    "The model gave me a best score of 0.8355541226745274\n",
    "\n",
    "Score on kaggle 0.84440\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f66dc4",
   "metadata": {},
   "source": [
    "# Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c27db20",
   "metadata": {},
   "source": [
    "I will still use randomforest classifier, but this time with random search with validation set and see how my accuracy gets affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6bdbbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 9 candidates, totalling 9 fits\n",
      "best score 0.8066539377514987\n",
      "best parameters {'preprocessor__num__imputer__strategy': 'constant', 'my_classifier__n_estimators': 40, 'my_classifier__max_depth': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV #i imported the train_test_split to Further split\n",
    "#the original training set to a train and a validation set\n",
    "#I also imported the RandomizedSearchCv to perrform the random search\n",
    "from sklearn.model_selection import PredefinedSplit #PredefinedSplit Provides train/test indices to split data into train/test sets\n",
    "#using a predefined scheme specified by user with the test_fold parameter.\n",
    "param_grid = {\n",
    "    'preprocessor__num__imputer__strategy': ['constant'], #this is the strategy of completing missing data, it will be filled with constant \n",
    "    'my_classifier__n_estimators': [20, 30, 40],  #I changed my ranges to the number of trees to be used in the forest into: [20,30,40]\n",
    "    'my_classifier__max_depth':[100,200,300]#I set my  max depth ranges to [100, 200, 300] which are The number of splits that each decision tree is allowed to make.      \n",
    "}\n",
    "\n",
    "# Further split the original training set to a train and a validation set\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(\n",
    "    Xtr, ytr, train_size = 0.8, stratify = ytr, random_state = 2022)#the random_state parameter is used for initializing the internal random number generator\n",
    "#The stratify option instructs sklearn to divide the dataset into a test and training set with the ratio of class labels in the variable supplied.\n",
    "\n",
    "# Create a list where train data indices are -1 and validation data indices are 0\n",
    "# X_train2 (new training set), X_train\n",
    "split_index = [-1 if x in X_train2.index else 0 for x in Xtr.index]\n",
    "\n",
    "# Use the list to create PredefinedSplit\n",
    "pds = PredefinedSplit(test_fold = split_index)\n",
    "grid_search = RandomizedSearchCV( #grid_search\n",
    "    full_pipline, param_grid, cv=pds, verbose=1, n_jobs=2,\n",
    "    # number of random trials\n",
    "    n_iter=10,\n",
    "    scoring='roc_auc')#The degree of separability/distinction or intermingling/crossover between the forecasts of the two classes is shown by the ROC-AUC.\n",
    "\n",
    "grid_search.fit(Xtr, ytr) #fitting my data into grid_search results\n",
    "\n",
    "print('best score {}'.format(grid_search.best_score_))\n",
    "print('best parameters {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82967786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the resulting model is the same pipeline with the best hyperparameters\n",
    "# trained on the full training set. we can use it directly\n",
    "ypred=grid_search.predict(Xts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7749eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()# creating dataframe for the submission\n",
    "submission['id'] = Xts.index#using the column index of x test values to fill submission['id'] column\n",
    "submission['match'] = grid_search.predict_proba(Xts)[:,1]#predicting the probabilities and filling submission['match'] column with their values\n",
    "submission.to_csv('sample_submission_walkthrough.csv', index=False)#generating the submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f1ae90",
   "metadata": {},
   "source": [
    "# Trial 3 with using randomsearch with validation set\n",
    "\n",
    "random search CV give us local optimal (may be good enough and even more generalizable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43098955",
   "metadata": {},
   "source": [
    "# Expectation\n",
    "\n",
    "I expected to get a higher score after using randomsearch with validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb7f26d",
   "metadata": {},
   "source": [
    "# Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a021c1f4",
   "metadata": {},
   "source": [
    "After running the code,the best hyperparameters that was defined by randomsearch with validation set were : \n",
    "\n",
    "n_estimators: 40\n",
    "\n",
    "max_depth: 100\n",
    "\n",
    "with using imputer__strategy: 'constant'\n",
    "\n",
    "The model gave me a best score of 0.8066539377514987\n",
    "\n",
    "Score on kaggle 0.82700\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58288f6a",
   "metadata": {},
   "source": [
    "# Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97e8668",
   "metadata": {},
   "source": [
    "I will still use random search with  validation set\n",
    "\n",
    "bur I will change 'imputer__strategy': ['median'],\n",
    "\n",
    "n_estimators': [100, 120, 140], \n",
    "\n",
    "max_depth':[5,10,15] ,\n",
    "\n",
    "n_iter=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "823e1aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 6 candidates, totalling 6 fits\n",
      "best score 0.8298636774246531\n",
      "best parameters {'preprocessor__num__imputer__strategy': 'median', 'my_classifier__n_estimators': 140, 'my_classifier__max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "param_grid = {\n",
    "    'preprocessor__num__imputer__strategy': ['median'],\n",
    "#this is the strategy of completing missing data, it will be filled with the median \n",
    "    'my_classifier__n_estimators': [100, 120, 140],  \n",
    "      #I changed my ranges to the number of trees to be used in the forest into: [100,120,140]\n",
    "    'my_classifier__max_depth':[5,10,15] #I set my  max depth ranges to [5, 10, 15] which are The number of splits that each decision tree is allowed to make.        \n",
    "}\n",
    "\n",
    "\n",
    "grid_search = RandomizedSearchCV(\n",
    "    full_pipline, param_grid, cv=pds, verbose=1,# showing more 'wordy' information\n",
    "    n_jobs=2, # n_jobs means the cucurrent number of jobs\n",
    "    # number of random trials\n",
    "    n_iter=6,\n",
    "    scoring='roc_auc')#The degree of separability/distinction or intermingling/crossover between the forecasts of the two classes is shown by the ROC-AUC.\n",
    "\n",
    "grid_search.fit(Xtr, ytr)\n",
    "\n",
    "print('best score {}'.format(grid_search.best_score_)) #printing best scores\n",
    "print('best parameters {}'.format(grid_search.best_params_)) #print best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a806032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the resulting model is the same pipeline with the best hyperparameters\n",
    "# trained on the full training set. we can use it directly\n",
    "ypred=grid_search.predict(Xts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0bc403a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()# creating dataframe for the submission\n",
    "submission['id'] = Xts.index#using the column index of x test values to fill submission['id'] column\n",
    "submission['match'] = grid_search.predict_proba(Xts)[:,1]#predicting the probabilities and filling submission['match'] column with their values\n",
    "submission.to_csv('sample_submission_walkthrough.csv', index=False)#generating the submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5609b097",
   "metadata": {},
   "source": [
    "# Trial 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9eae5b",
   "metadata": {},
   "source": [
    "# Expectation\n",
    "\n",
    "I expected to get a higher score after changing the ranges/values of my model's hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd18de5",
   "metadata": {},
   "source": [
    "# Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65196b25",
   "metadata": {},
   "source": [
    "After running the code,the best hyperparameters that was defined by randomsearch with validation set were : \n",
    "\n",
    "n_estimators: 140\n",
    "\n",
    "max_depth: 5\n",
    "\n",
    "with using imputer__strategy: 'median'\n",
    "\n",
    "The model gave me a best score of 0.8298636774246531\n",
    "\n",
    "Score on kaggle 0.82827\n",
    "\n",
    "my best score and score on kaggle both increased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e9a7cb",
   "metadata": {},
   "source": [
    "# plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399cd241",
   "metadata": {},
   "source": [
    "I will implement support vector machine model using bayesian search to get the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ddee7817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "best score 0.8324873096446701\n",
      "best score OrderedDict([('my_svc__C', 2.2841098739835276e-06), ('my_svc__degree', 6), ('my_svc__gamma', 5.005418606010382e-05), ('my_svc__kernel', 'poly')])\n"
     ]
    }
   ],
   "source": [
    "# Let's try this with SVM model\n",
    "from skopt import BayesSearchCV #for Bayesian optimization over hyper parameters.\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.svm import SVC #to implement svc model\n",
    "\n",
    "SVC_pipline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('my_svc', SVC(class_weight='balanced',probability=True)) #setting probability to true to be able to use probna() later when submission\n",
    "        #class_weight='balanced' assigns the class weights inversely proportional to their respective frequencies\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# define ranges for bayes search\n",
    "bayes_search = BayesSearchCV(\n",
    "    SVC_pipline,\n",
    "    {\n",
    "        'my_svc__C': Real(1e-8, 1e+8, prior='log-uniform'), #ranges for c which is the Penalty parameter of the error term.\n",
    "        'my_svc__gamma': Real(1e-9, 1e+1, prior='log-uniform'), #ranges for gamma, the gamma parameter defines how far the influence of a single training example reaches\n",
    "        'my_svc__degree': Integer(1,8), #degree ranges,the degree of the polynomial kernel function \n",
    "        'my_svc__kernel': Categorical(['poly','linear', 'rbf']), #kernel ranges,A kernel is a function used in SVM for helping to solve problems\n",
    "     \n",
    "    },\n",
    "    # number of trials \n",
    "    n_iter=6,\n",
    "    random_state=0,#the random_state parameter is used for initializing the internal random number generator\n",
    "    verbose=1,# showing more 'wordy' information\n",
    "    cv=pds,\n",
    ")\n",
    "\n",
    "bayes_search.fit(Xtr, ytr)\n",
    "\n",
    "print('best score {}'.format(bayes_search.best_score_))\n",
    "print('best parameters {}'.format(bayes_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63e22b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the resulting model is the same pipeline with the best hyperparameters\n",
    "# trained on the full training set. we can use it directly\n",
    "ypred=bayes_search.predict(Xts) #predicting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a27af22",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame() # creating dataframe for the submission\n",
    "submission['id'] = Xts.index #using the column index of x test values to fill submission['id'] column\n",
    "submission['match'] = bayes_search.predict_proba(Xts)[:,1] #predicting the probabilities and filling submission['match'] column with their values\n",
    "submission.to_csv('sample_submission_walkthrough.csv', index=False)#generating the submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15adf6a",
   "metadata": {},
   "source": [
    "# Trial 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be68a275",
   "metadata": {},
   "source": [
    "I used support vector machine using bayesian search to get the best hyperparameters\n",
    "\n",
    "Support vector machines are supervised learning models with associated learning algorithms that analyze data for classification and regression analysis. \n",
    "\n",
    "Bayesian optimization, a model-based method for finding the minimum of a function, has recently been applied to machine learning hyperparameter tuning, with results suggesting this approach can achieve better performance on the test set while requiring fewer iterations than random search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8c01be",
   "metadata": {},
   "source": [
    "# Expectation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd10061",
   "metadata": {},
   "source": [
    "I expected to get a higher score after using support vector machines with bayesian search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ca3eba",
   "metadata": {},
   "source": [
    "# Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c534abd",
   "metadata": {},
   "source": [
    "After running the code,the best hyperparameters that was defined by bayesian search were : \n",
    "    \n",
    "C= 2.2841098739835276e-06\n",
    "\n",
    "degree = 6\n",
    "\n",
    "gamma=  5.005418606010382e-05\n",
    "\n",
    "kernel = 'poly'\n",
    "\n",
    "\n",
    "The model gave me a best score of 0.8324873096446701\n",
    "\n",
    "Score on kaggle 0.50271\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4bd246",
   "metadata": {},
   "source": [
    "# plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b2a929",
   "metadata": {},
   "source": [
    "I will change ranges of hyperparameters to \n",
    "\n",
    "'C': Real(2e-5, 1e+10, prior='log-uniform')\n",
    "\n",
    "'gamma': Real(3e-6, 2e+4, prior='log-uniform')\n",
    "\n",
    "and i will set \n",
    "\n",
    "'kernel': ['poly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b7dc3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "best score 0.8282571912013537\n",
      "best parameters OrderedDict([('my_svc__C', 0.052329516515125955), ('my_svc__degree', 3), ('my_svc__gamma', 42.72743322299447), ('my_svc__kernel', 'poly')])\n"
     ]
    }
   ],
   "source": [
    "SVC_pipline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('my_svc', SVC(class_weight='balanced',probability=True)) #setting probability to true to be able to use probna() later when submission\n",
    "        #class_weight='balanced' assigns the class weights inversely proportional to their respective frequencies\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# define ranges for bayes search\n",
    "bayes_search = BayesSearchCV(\n",
    "    SVC_pipline,\n",
    "    {\n",
    "        'my_svc__C': Real(2e-5, 1e+10, prior='log-uniform'), #ranges for c which is the Penalty parameter of the error term.\n",
    "        'my_svc__gamma': Real(3e-6, 2e+4, prior='log-uniform'), #ranges for gamma, the gamma parameter defines how far the influence of a single training example reaches\n",
    "        'my_svc__degree': Integer(1,8), #degree ranges, the degree of the polynomial kernel function \n",
    "        'my_svc__kernel': Categorical([ 'poly']), #kernel ranges,A kernel is a function used in SVM for helping to solve problems\n",
    "     \n",
    "    },\n",
    "    # number of trials \n",
    "    n_iter=6,\n",
    "    random_state=0,#the random_state parameter is used for initializing the internal random number generator\n",
    "    verbose=1,# showing more 'wordy' information\n",
    "    cv=pds,\n",
    ")\n",
    "\n",
    "bayes_search.fit(Xtr, ytr)\n",
    "\n",
    "print('best score {}'.format(bayes_search.best_score_))\n",
    "print('best parameters {}'.format(bayes_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ff08453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the resulting model is the same pipeline with the best hyperparameters\n",
    "# trained on the full training set. we can use it directly\n",
    "ypred=bayes_search.predict(Xts) #predicting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8397fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame() # creating dataframe for the submission\n",
    "submission['id'] = Xts.index #using the column index of x test values to fill submission['id'] column\n",
    "submission['match'] = bayes_search.predict_proba(Xts)[:,1] #predicting the probabilities and filling submission['match'] column with their values\n",
    "submission.to_csv('sample_submission_walkthrough.csv', index=False)#generating the submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab9f72e",
   "metadata": {},
   "source": [
    "# Trial 6\n",
    "\n",
    "I changed ranges of hyperparameters to \n",
    "\n",
    "'C': Real(2e-5, 1e+10, prior='log-uniform')\n",
    "\n",
    "'gamma': Real(3e-6, 2e+4, prior='log-uniform')\n",
    "\n",
    "and i will set \n",
    "\n",
    "'kernel': ['poly']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113e1a55",
   "metadata": {},
   "source": [
    "# Expectation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe2ac1a",
   "metadata": {},
   "source": [
    "I expected to get a higher score after changing the ranges of my support vector machine model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b0621",
   "metadata": {},
   "source": [
    "# Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7464db30",
   "metadata": {},
   "source": [
    "After running the code,the best hyperparameters that was defined by bayesian search were : \n",
    "    \n",
    "C= 0.052329516515125955\n",
    "\n",
    "degree = 3\n",
    "\n",
    "gamma=  42.72743322299447\n",
    "\n",
    "with using kernel = 'poly'\n",
    "\n",
    "\n",
    "The model gave me a best score of 0.8282571912013537\n",
    "\n",
    "Score on kaggle 0.81313\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbfc41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
